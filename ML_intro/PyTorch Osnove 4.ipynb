{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4","authorship_tag":"ABX9TyPADi97Vbm0lz72hLIcWWb6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **PyTorch Osnove 4: Primer ReÅ¡avanja Konkretnog Problema**\n","\n","**Kurs:** KSMF1  \n","**Trajanje:** ~45 min  \n","**Preduslovi:** Pytorch Osnove 1, 2 i 3  \n","\n","---"],"metadata":{"id":"0yOaOueS0X_L"}},{"cell_type":"markdown","source":["## Ciljevi Sekcije\n","\n","Do kraja ove sekcije, nauÄiÄ‡ete da:\n","\n","Here's the Serbian translation:\n","\n","- Primeniti PyTorch na realistiÄan problem klasifikacije u fizici\n","- Profesionalno koristiti PyTorch apstrakcije podataka (Dataset, DataLoader)\n","- Graditi i trenirati neuronske mreÅ¾e za multiklasnu klasifikaciju\n","- Proceniti performanse klasifikacije koristeÄ‡i standardne metrike\n","- Implementirati kompletan ML radni tok od podataka do implementacije\n","\n","---"],"metadata":{"id":"Z-JvsnmF0Y40"}},{"cell_type":"markdown","source":["# **Deo 7: PraktiÄan Primer - Problem Identifikacije ÄŒestica**"],"metadata":{"id":"c8Xi9cQ20aJZ"}},{"cell_type":"markdown","source":["## 7.1 Uvod\n","\n","DobrodoÅ¡li u **CMS izazov klasifikacije Äestica**! ğŸ”¬\n","\n","Zamislite da radite na eksperimentu iz fizike Äestica (CERN-ov Veliki hadronski sudaraÄ). Kada visokoenergetske Äestice proÄ‘u kroz detektor, moÅ¾ete da merite razliÄita svojstva.\n","\n","VaÅ¡ zadatak: Napraviti ML klasifikator koji Ä‡e **klasifikovati koji tip Äestice je proÅ¡ao kroz detektor** na osnovu ovih merenja.\n","\n","**Izazov:**\n","- **ÄŒestice:** Elektroni, Mioni, Pioni (3 klase)\n","- **Merenja:** Depozit energije, zakrivljenost traga, vreme leta, obrazac pogodaka (4 karakteristike)\n","- **Cilj:** Izgraditi klasifikator sa >90% taÄnoÅ¡Ä‡u"],"metadata":{"id":"criUZi241XHV"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import classification_report, confusion_matrix\n","import seaborn as sns\n","\n","# Postavi random seed zbog reproducibilnosti\n","torch.manual_seed(42)\n","np.random.seed(42)\n","\n","print(\"ğŸ”¬ CMS Particle Classification Challenge\")\n","print(\"Goal: Classify particles from detector readings\")"],"metadata":{"id":"TmjS-zDU1g5C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"wTboKleK1isg"}},{"cell_type":"markdown","source":["## 7.2 Prikupljanje podataka\n","\n","Svaki Machine Learning workflow poÄinje sa prikupljanjem, analizom, i pripremom podataka!"],"metadata":{"id":"vfppTz9i1tcS"}},{"cell_type":"markdown","source":["### Generisanje RealistiÄnih Podataka ÄŒestica\n","\n","PoÅ¡to nemamo pristup pravim eksperimentalnim podacima (i oni su mnogo sloÅ¾eniji od ovog primera), hajde da **simuliramo podatke iz detektora Äestica**, sa pojednostavljenim korelacijama i obrascima Å¡uma, Äisto da imamo sa Äime da radimo.\n","\n","GenerisaÄ‡emo 2000 uzoraka realistiÄnih podataka detektora Äestica sa pojednostavljenim korelacijama zasnovanim na fizici.\n","\n","Svaki uzorak Ä‡e imati 4 karakteristike:\n","*   **Depozit energije**: Energija ostavljena u kalorimetru (GeV)\n","*   **Zakrivljenost traga**: Zakrivljenost u magnetnom polju (1/GeVÂ·c)\n","*   **Vreme leta**: Vreme putovanja kroz detektor (ns)\n","*   **Obrazac pogodaka**: Broj aktiviranih slojeva detektora\n","\n","I svaki uzorak Ä‡e biti oznaÄen kao:\n","*   **0: Elektron** (laki lepton, elektromagnetne interakcije)\n","*   **1: Mion** (teÅ¾ak lepton, minimalne interakcije)\n","*   **2: Pion** (mezon, jake interakcije)\n","\n","Pretpostavljamo da su za svaku klasu Äestica sve 4 karakteristike **normalno distribuirane**, ali sa razliÄitim parametrima distribucije.\n","\n","*Zapamtite: U pravim radnim tokovima ne generiÅ¡ete podatke! Prikupljate ih! To znaÄi da ne znate prethodne distribucije. VaÅ¡ cilj je da koristite svoju ekspertizu da ih pretpostavite, a zatim izgradite najbolji model za vaÅ¡e podatke.*"],"metadata":{"id":"0bsaXHTU2Jyf"}},{"cell_type":"code","source":["def generate_particle_dataset(n_samples=2000):\n","    \"\"\"\n","    GeneriÅ¡e izmiÅ¡ljene podatke detektora Äestica sa korelacijama zasnovanim na fizici.\n","\n","    Karakteristike:\n","    - energy_deposit: Energija ostavljena u kalorimetru (GeV)\n","    - track_curvature: Zakrivljenost u magnetnom polju (1/GeVÂ·c)\n","    - time_of_flight: Vreme putovanja kroz detektor (ns)\n","    - hit_pattern: Broj aktiviranih slojeva detektora\n","\n","    Klase:\n","    - 0: Elektron (laki lepton, elektromagnetne interakcije)\n","    - 1: Mion (teÅ¾ak lepton, minimalne interakcije)\n","    - 2: Pion (mezon, jake interakcije)\n","    \"\"\"\n","\n","    torch.manual_seed(42)\n","    np.random.seed(42)\n","\n","    n_per_class = n_samples // 3\n","\n","    # === ELEKTRONI ===\n","    # Visok depozit energije (elektromagnetni pljuskovi)\n","    # Visoka zakrivljenost (nizak impuls zbog radijacije)\n","    # Brzi (blizu brzine svetlosti)\n","    # Umeren obrazac pogodaka (staju u kalorimetru)\n","\n","    electron_energy = torch.normal(12.0, 2.5, (n_per_class,))\n","    electron_curvature = torch.normal(0.85, 0.15, (n_per_class,))\n","    electron_tof = torch.normal(2.1, 0.2, (n_per_class,))\n","    electron_hits = torch.normal(8.5, 1.2, (n_per_class,))\n","\n","    # === MIONI ===\n","    # Nizak depozit energije (minimalno jonizujuÄ‡e Äestice)\n","    # Niska zakrivljenost (visok impuls, prodirne)\n","    # Umerena brzina (masivna Äestica)\n","    # Visok obrazac pogodaka (prodiru kroz ceo detektor)\n","\n","    muon_energy = torch.normal(2.8, 0.8, (n_per_class,))\n","    muon_curvature = torch.normal(0.25, 0.08, (n_per_class,))\n","    muon_tof = torch.normal(2.4, 0.25, (n_per_class,))\n","    muon_hits = torch.normal(12.2, 1.5, (n_per_class,))\n","\n","    # === PIONI ===\n","    # Srednji depozit energije (hadronske interakcije)\n","    # Varijabilna zakrivljenost (Å¡irok spektar impulsa)\n","    # Sporiji (teÅ¾i od elektrona)\n","    # Varijabilan obrazac pogodaka (zavisi od interakcije)\n","\n","    pion_energy = torch.normal(7.5, 3.0, (n_per_class,))\n","    pion_curvature = torch.normal(0"],"metadata":{"id":"mDz8x5_M5QZe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Vizualizacija i Razumevanje Podataka\n","\n","Sada kada smo simulirali prikupljanje naÅ¡ih podataka, moÅ¾emo poÄeti sa prvim korakom svakog ML radnog toka.\n","\n","Prvi korak je uvek da **razumete podatke**!\n","\n","Za ovo Ä‡ete se osloniti na dve stvari:\n","1. **VaÅ¡a ekspertiza u domenu** (tj. poznavanje fizike Äestica, kakva ponaÅ¡anja oÄekujete, kakve distribucije oÄekujete na osnovu fizike, itd.)\n","2. **Analiza i vizualizacija podataka** (tj. koriÅ¡Ä‡enje vaÅ¡ih statistiÄkih veÅ¡tina da analizirate vaÅ¾ne statistiÄke parametre podataka, i moguÄ‡nost da ih vizualizujete na najintuitivniji naÄin)"],"metadata":{"id":"s1qhdHW75ZzF"}},{"cell_type":"code","source":["# Kreiramo vizualizaciju podataka\n","fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n","colors = ['red', 'blue', 'green']\n","particle_names = ['Electron', 'Muon', 'Pion']\n","\n","# Distribucije karakteristika\n","for i, (feature_name, ax) in enumerate(zip(feature_names, axes.flat[:4])):\n","    for class_id, (particle_name, color) in enumerate(zip(particle_names, colors)):\n","        class_mask = labels == class_id\n","        ax.hist(features[class_mask, i].numpy(), alpha=0.6, label=particle_name,\n","                color=color, bins=40, density=True)\n","    ax.set_xlabel(feature_name)\n","    ax.set_ylabel('Density')\n","    ax.set_title(f'Distribution: {feature_name}')\n","    ax.legend()\n","    ax.grid(True, alpha=0.3)\n","\n","# Analiza korelacija\n","axes[1, 0].remove()\n","axes[1, 1].remove()\n","correlation_ax = fig.add_subplot(2, 3, (5, 6))\n","\n","# IzraÄunaj matricu korelacije\n","correlation_matrix = torch.corrcoef(features.T)\n","sns.heatmap(correlation_matrix.numpy(),\n","            xticklabels=['Energy', 'Curvature', 'ToF', 'Hits'],\n","            yticklabels=['Energy', 'Curvature', 'ToF', 'Hits'],\n","            annot=True, cmap='coolwarm', center=0,\n","            ax=correlation_ax)\n","correlation_ax.set_title('Feature Correlations')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"ğŸ” Physics Insights:\")\n","print(\"ğŸ“Š Electrons: High energy deposit, high curvature (low momentum)\")\n","print(\"ğŸš€ Muons: Low energy deposit, low curvature (high momentum), many hits\")\n","print(\"âš›ï¸  Pions: Intermediate properties, high variability\")\n","print(\"ğŸ”— Correlations reveal realistic physics relationships!\")"],"metadata":{"id":"Mi1IPlwZ7LxY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"QbjXWApq8fZ-"}},{"cell_type":"markdown","source":["## 7.3 Priprema podataka\n","\n","Sada kada imamo i razumemo naÅ¡e podatke, vreme je da pripremimo naÅ¡ dataset za ML workflow.\n","\n","To znaÄi da Ä‡emo ga spakovati kao `Dataset` potklasu, izvrÅ¡iti **podelu** i **normalizaciju**, i kreirati `DataLoader` koji Ä‡e za nas rukovati **batch-ovanjem** i **meÅ¡anjem**."],"metadata":{"id":"c0WB2jW18rw3"}},{"cell_type":"markdown","source":["### Pakovanje Podataka u `Dataset` potklasu\n","\n","Kao Å¡to smo nauÄili u Delu 2, PyTorch dolazi sa klasom koja se zove `Dataset` koja sluÅ¾i kao **Å¡ablon** za lakÅ¡e rukovanje podacima i usmeravanje u model. Umesto direktnog rada sa sirovim podacima, kreiraÄ‡emo klasu `ParticleDataset` (potklasu od `Dataset`) koja Ä‡e manipulisati naÅ¡im sirovim podacima i pomoÄ‡i nam sa njihovim izvlaÄenjem i prosleÄ‘ivanjem."],"metadata":{"id":"qh0EcfoE9iPm"}},{"cell_type":"code","source":["class ParticleDataset(Dataset):\n","    \"\"\"\n","    PyTorch Dataset potklasa za klasifikaciju Äestica.\n","    Ova klasa enkapsulira naÅ¡e podatke i pruÅ¾a interfejs\n","    koji PyTorch-ov DataLoader oÄekuje.\n","    \"\"\"\n","    def __init__(self, features, labels, transform=None):\n","        \"\"\"\n","        Args:\n","            features: Tenzor oblika (n_samples, n_features)\n","            labels: Tenzor oblika (n_samples,)\n","            transform: Opciona transform funkcija\n","        \"\"\"\n","        self.features = features.float()  # Osiguraj float32\n","        self.labels = labels.long()       # Osiguraj long za klasifikaciju\n","        self.transform = transform\n","\n","        # ÄŒuvaj metapodatke\n","        self.n_samples, self.n_features = features.shape\n","        self.n_classes = len(torch.unique(labels))\n","        self.feature_names = ['energy_deposit', 'track_curvature', 'time_of_flight', 'hit_pattern']\n","        self.class_names = ['Electron', 'Muon', 'Pion']\n","\n","    def __len__(self):\n","        \"\"\"Vrati broj uzoraka.\"\"\"\n","        return self.n_samples\n","\n","    def __getitem__(self, idx):\n","        \"\"\"Vrati jedan uzorak (karakteristike, label) datog indeksa.\"\"\"\n","        sample_features = self.features[idx]\n","        sample_label = self.labels[idx]\n","\n","        if self.transform:\n","            sample_features = self.transform(sample_features)\n","\n","        return sample_features, sample_label\n","\n","    # SledeÄ‡e su opcione metode koje Ä‡e pomoÄ‡i sa pripremom podataka\n","    def get_class_weights(self):\n","        \"\"\"IzraÄunaj teÅ¾ine klasa za rukovanje nebalansiranim podacima.\"\"\"\n","        class_counts = torch.bincount(self.labels)\n","        total_samples = len(self.labels)\n","        weights = total_samples / (self.n_classes * class_counts.float())\n","        return weights\n","\n","    def get_statistics(self):\n","        \"\"\"Vrati statistiku dataset-a.\"\"\"\n","        return {\n","            'feature_means': self.features.mean(dim=0),\n","            'feature_stds': self.features.std(dim=0),\n","            'class_counts': torch.bincount(self.labels),\n","            'total_samples': self.n_samples\n","        }\n","\n","# Kreiraj instancu dataset-a\n","full_dataset = ParticleDataset(features, labels)\n","\n","print(\"=== PyTorch-Ready Dataset Created ===\")\n","print(f\"Dataset size: {len(full_dataset)}\")\n","print(f\"Features: {full_dataset.n_features}\")\n","print(f\"Classes: {full_dataset.n_classes}\")\n","\n","# PrikaÅ¾i statistiku dataset-a\n","stats = full_dataset.get_statistics()\n","print(f\"\\nDataset Statistics:\")\n","print(f\"Feature means: {stats['feature_means']}\")\n","print(f\"Feature stds: {stats['feature_stds']}\")\n","print(f\"Class distribution: {stats['class_counts']}\")\n","\n","# Testiraj indeksiranje dataset-a\n","sample_features, sample_label = full_dataset[0]\n","print(f\"\\nSample test:\")\n","print(f\"First sample features: {sample_features}\")\n","print(f\"First sample label: {sample_label} ({full_dataset.class_names[sample_label]})\")"],"metadata":{"id":"nkiz-8ya-vDw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Podela i Normalizacija Podataka\n","\n","Sada kada smo napravili Äiste metode za manipulaciju naÅ¡im podacima, vreme je da ih pripremimo za treniranje.\n","\n","PodeliÄ‡emo naÅ¡e podatke na Train/Validation/Test skupove (70:15:15) i normalizovati karakteristike da osiguramo da su svi podaci na istoj skali."],"metadata":{"id":"FKNyX250_3uE"}},{"cell_type":"code","source":["# Podela na train/validation/test\n","def create_data_splits(dataset, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n","    \"\"\"Kreiraj train/validation/test skupove koristeÄ‡i PyTorch-ov random_split.\"\"\"\n","    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6 # Odnosi moraju da se sumiraju u 1 (do na numeriÄku greÅ¡ku na Å¡estoj decimali)\n","\n","    n_total = len(dataset)\n","    n_train = int(train_ratio * n_total)\n","    n_val = int(val_ratio * n_total)\n","    n_test = n_total - n_train - n_val  # Ovo osigurava da i n_test bude ceo broj, a da se uzorci ne ponavljaju\n","\n","    train_dataset, val_dataset, test_dataset = random_split(\n","        dataset, [n_train, n_val, n_test],\n","        generator=torch.Generator().manual_seed(42)\n","    )\n","\n","    return train_dataset, val_dataset, test_dataset\n","\n","# Kreiraj podele\n","train_dataset, val_dataset, test_dataset = create_data_splits(full_dataset)\n","\n","print(\"=== Data Splitting ===\")\n","print(f\"Training samples:   {len(train_dataset):4d} ({len(train_dataset)/len(full_dataset)*100:.1f}%)\")\n","print(f\"Validation samples: {len(val_dataset):4d} ({len(val_dataset)/len(full_dataset)*100:.1f}%)\")\n","print(f\"Test samples:       {len(test_dataset):4d} ({len(test_dataset)/len(full_dataset)*100:.1f}%)\")\n","\n","# Normalizacija karakteristika koristeÄ‡i statistiku dataset-a\n","def compute_normalization_stats(dataset):\n","    \"\"\"IzraÄunaj statistike normalizacije iz dataset-a.\"\"\"\n","    # Izvuci sve karakteristike iz dataset-a\n","    features_list = []\n","    for i in range(len(dataset)):\n","        features, _ = dataset[i]\n","        features_list.append(features.unsqueeze(0))\n","\n","    all_features = torch.cat(features_list, dim=0)\n","    mean = all_features.mean(dim=0)\n","    std = all_features.std(dim=0)\n","    return mean, std\n","\n","# IzraÄunaj normalizaciju samo iz podataka za treniranje\n","train_mean, train_std = compute_normalization_stats(train_dataset)\n","\n","print(f\"\\nNormalization Statistics (from training data):\")\n","print(f\"Mean: {train_mean}\")\n","print(f\"Std:  {train_std}\")\n","\n","# Kreiraj transform za normalizaciju\n","class Normalize:\n","    \"\"\"Transform za normalizaciju karakteristika.\"\"\"\n","    def __init__(self, mean, std):\n","        self.mean = mean\n","        self.std = std\n","\n","    def __call__(self, features):\n","        return (features - self.mean) / (self.std + 1e-8)  # Dodaj malo epsilon\n","\n","normalize = Normalize(train_mean, train_std)\n","\n","# Primeni normalizaciju na dataset-ove\n","class NormalizedDataset(Dataset):\n","    \"\"\"Wrapper koji primenjuje transform normalizacije.\"\"\"\n","    def __init__(self, dataset, transform):\n","        self.dataset = dataset\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        features, label = self.dataset[idx]\n","        if self.transform:\n","            features = self.transform(features)\n","        return features, label\n","\n","# Kreiraj normalizovane dataset-ove\n","train_dataset_norm = NormalizedDataset(train_dataset, normalize)\n","val_dataset_norm = NormalizedDataset(val_dataset, normalize)\n","test_dataset_norm = NormalizedDataset(test_dataset, normalize)\n","\n","print(\"âœ… Normalization applied to all splits\")"],"metadata":{"id":"y0pGarpFAyZ9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### UÄitavanje, Batching i MeÅ¡anje Podataka\n","\n","Sada Ä‡emo kreirati data loader-e za svaki od naÅ¡a 3 podskupa dataset-a koristeÄ‡i `DataLoader` klasu. `DataLoader` je napravljen da uzima `Dataset` instance i ima ugraÄ‘ene metode za batch-ovanje i meÅ¡anje podataka. TakoÄ‘e pruÅ¾a funkcionalnost za koriÅ¡Ä‡enje viÅ¡e CPU jezgara za paralelno uÄitavanje podataka (num_workers)."],"metadata":{"id":"Ywzs2ITdAzHV"}},{"cell_type":"code","source":["# Kreiraj DataLoader-e\n","def create_dataloaders(train_dataset, val_dataset, test_dataset,\n","                      batch_size=64, num_workers=0):\n","    \"\"\"Kreiraj DataLoader-e za treniranje, validaciju i testiranje.\"\"\"\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,           # PomeÅ¡aj podatke za treniranje\n","        num_workers=num_workers,\n","        pin_memory=True,        # Ubrzaj GPU transfer\n","        drop_last=False         # Ne odbacuj nepotpune batch-ove\n","    )\n","\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,          # Nema potrebe da meÅ¡aÅ¡ validaciju\n","        num_workers=num_workers,\n","        pin_memory=True,\n","        drop_last=False\n","    )\n","\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,          # Nema potrebe da meÅ¡aÅ¡ test\n","        num_workers=num_workers,\n","        pin_memory=True,\n","        drop_last=False\n","    )\n","\n","    return train_loader, val_loader, test_loader\n","\n","# Kreiraj DataLoader-e\n","batch_size = 64\n","train_loader, val_loader, test_loader = create_dataloaders(\n","    train_dataset_norm, val_dataset_norm, test_dataset_norm,\n","    batch_size=batch_size\n",")\n","\n","print(\"=== DataLoaders Created ===\")\n","print(f\"Batch size: {batch_size}\")\n","print(f\"Training batches:   {len(train_loader)}\")\n","print(f\"Validation batches: {len(val_loader)}\")\n","print(f\"Test batches:       {len(test_loader)}\")\n","\n","# Testiraj DataLoader\n","print(f\"\\nDataLoader Test:\")\n","for batch_features, batch_labels in train_loader:\n","    print(f\"Batch features shape: {batch_features.shape}\")\n","    print(f\"Batch labels shape: {batch_labels.shape}\")\n","    print(f\"Feature range after normalization: [{batch_features.min():.3f}, {batch_features.max():.3f}]\")\n","    print(f\"Unique labels in batch: {torch.unique(batch_labels)}\")\n","    break  # Samo prikaÅ¾i prvi batch\n","\n","print(\"ğŸš€ Data pipeline ready for training!\")"],"metadata":{"id":"KGD_sxGjCZBZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"-iElUdVECZ_0"}},{"cell_type":"markdown","source":["## 7.4 Gradnja i Treniranje Klasifikatora\n","\n","NaÅ¡i podaci su spremni za obradu unutar naÅ¡eg modela! MeÄ‘utim, prvo treba da izgradimo model.\n","\n","Razmislimo o tome kakav model nam je potreban:\n","1. PoÅ¡to je ovo problem klasifikacije sa viÅ¡e opcija, praviÄ‡emo **multiklasni klasifikator** koristeÄ‡i neuronsku mreÅ¾u\n","2. Ne Å¾elimo da naÅ¡ model bude previÅ¡e jednostavan i neekspresivan, ali takoÄ‘e ne Å¾elimo da ga uÄinimo previÅ¡e sloÅ¾enim, fleksibilnim i preekspresivnim.\n","\n","Na osnovu sloÅ¾enosti naÅ¡eg dataset-a (4 karakteristike i 3 klase), moÅ¾emo poÄeti sa neÄim priliÄno jednostavnim, ali ipak ne previÅ¡e sloÅ¾enim. Izaberimo mreÅ¾u sa 3 sloja (da joj damo dovoljno moÄ‡i apstrakcije), i veliÄine 64, 32, i 16 respektivno (da obezbedimo dovoljnu rezoluciju za svaki nivo apstrakcije).\n","\n","*Zapamtite: Ne postoji ispravan ili pogreÅ¡an metod za biranje ovih hiperparametara - samo pokuÅ¡aji i greÅ¡ke pomoÄ‡u informisanih pretpostavki, kao i vaÅ¡a intuicija i iskustvo. Zbog toga i koristimo validaciju: da podeÅ¡avamo naÅ¡u mreÅ¾u na osnovu pokuÅ¡aja i greÅ¡aka.*"],"metadata":{"id":"udFrGDApCbIs"}},{"cell_type":"markdown","source":["### GraÄ‘enje Arhitekture MreÅ¾e\n","\n","Hajde da definiÅ¡emo naÅ¡ multiklasni klasifikator kao prilagoÄ‘enu `nn.Module` potklasu:"],"metadata":{"id":"Alhioe4BGGxk"}},{"cell_type":"code","source":["class ParticleClassifier(nn.Module):\n","    \"\"\"\n","    Neuronska mreÅ¾a za klasifikaciju Äestica.\n","    Arhitektura dizajnirana za fiziÄki problem:\n","    - Ulaz: 4 varijable iz detektora\n","    - Skriveni slojevi: Izdvajaju sloÅ¾ene interakcije varijabli\n","    - Izlaz: 3 klase (Elektron, Mion, Pion)\n","    \"\"\"\n","    def __init__(self, input_size=4, hidden_sizes=[64, 32, 16], num_classes=3, dropout_prob=0.2):\n","        super(ParticleClassifier, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_sizes = hidden_sizes\n","        self.num_classes = num_classes\n","        self.dropout_prob = dropout_prob\n","\n","        # Izgradi mreÅ¾u dinamiÄki\n","        layers = []\n","        in_size = input_size\n","\n","        for hidden_size in hidden_sizes:\n","            layers.extend([\n","                nn.Linear(in_size, hidden_size),\n","                nn.BatchNorm1d(hidden_size),  # Batch normalizacija za stabilnost\n","                nn.ReLU(),\n","                nn.Dropout(dropout_prob)      # Regularizacija\n","            ])\n","            in_size = hidden_size\n","\n","        # Izlazni sloj (ne treba nam aktivacija na poslednjem sloju jer koristimo CrossEntropyLoss)\n","        layers.append(nn.Linear(in_size, num_classes))\n","        self.network = nn.Sequential(*layers)\n","\n","        # ÄŒuvaj metapodatke\n","        self.feature_names = ['energy_deposit', 'track_curvature', 'time_of_flight', 'hit_pattern']\n","        self.class_names = ['Electron', 'Muon', 'Pion']\n","\n","        # Inicijalizuj teÅ¾ine pravilno\n","        self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        \"\"\"Inicijalizuj teÅ¾ine mreÅ¾e koristeÄ‡i najbolje prakse.\"\"\"\n","        for module in self.modules():\n","            if isinstance(module, nn.Linear):\n","                nn.init.xavier_uniform_(module.weight)\n","                nn.init.constant_(module.bias, 0)\n","\n","    def forward(self, x):\n","        \"\"\"Forward pass kroz mreÅ¾u.\"\"\"\n","        return self.network(x)\n","\n","    def predict_proba(self, x):\n","        \"\"\"Dobij verovatnoÄ‡e klasa.\"\"\"\n","        self.eval()\n","        with torch.no_grad():\n","            logits = self.forward(x)\n","            probabilities = F.softmax(logits, dim=1)\n","        return probabilities\n","\n","    def predict(self, x):\n","        \"\"\"Dobij predviÄ‘anja klasa.\"\"\"\n","        probabilities = self.predict_proba(x)\n","        return torch.argmax(probabilities, dim=1)\n","\n","    def get_info(self):\n","        \"\"\"Dobij informacije o arhitekturi mreÅ¾e.\"\"\"\n","        total_params = sum(p.numel() for p in self.parameters())\n","        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n","        return {\n","            'architecture': f\"{self.input_size} â†’ {' â†’ '.join(map(str, self.hidden_sizes))} â†’ {self.num_classes}\",\n","            'total_parameters': total_params,\n","            'trainable_parameters': trainable_params,\n","            'dropout_probability': self.dropout_prob\n","        }"],"metadata":{"id":"arhsKw65GkGH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sada kada smo dizajnirali naÅ¡ `ParticleClassifier` Å¡ablon, vreme je da zapravo izgradimo (instanciramo) model:"],"metadata":{"id":"fnNmbJHYG_4i"}},{"cell_type":"code","source":["# Napravi model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = ParticleClassifier(\n","    input_size=4,\n","    hidden_sizes=[64, 32, 16],\n","    num_classes=3,\n","    dropout_prob=0.2\n",").to(device)\n","\n","print(\"=== Particle Classifier Created ===\")\n","info = model.get_info()\n","for key, value in info.items():\n","    print(f\"{key}: {value}\")\n","\n","print(f\"\\nModel architecture:\")\n","print(model)\n","\n","print(f\"\\nDevice: {device}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU: {torch.cuda.get_device_name()}\")"],"metadata":{"id":"p3KSac1mHNey"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### PodeÅ¡avanje Treninga\n","\n","Pre nego Å¡to napravimo naÅ¡u petlju za treniranje, hajde da podesimo sve komponente koje Ä‡e nam biti potrebne za nju. To znaÄi definisanje naÅ¡e **funkcije gubitka**, **optimizatora**, i **scheduler-a**.\n","\n","Funkcija gubitka koja najbolje odgovara multiklasnoj klasifikaciji je **Cross Entropy Loss**.\n","\n","NajÄeÅ¡Ä‡i optimizator je **Adam**, pa Ä‡emo se drÅ¾ati toga.\n","\n","Nismo ranije uveli scheduler-e, ali posmatrajte ih kao mehanizam koji prilagoÄ‘ava parametre treniranja tokom vremena da uÄini treniranje efikasnijim."],"metadata":{"id":"KMkqB30aI8Cd"}},{"cell_type":"code","source":["# PodeÅ¡avanje funkcije gubitka, optimizatora i scheduler-a\n","def create_training_components(model, train_dataset):\n","    \"\"\"Kreiraj funkciju gubitka, optimizator i scheduler.\"\"\"\n","    # IzraÄunaj teÅ¾ine klasa da bi se izaÅ¡lo na kraj sa bilo kakvim disbalansom podataka\n","    class_weights = full_dataset.get_class_weights().to(device)\n","    criterion = nn.CrossEntropyLoss(weight=class_weights)\n","\n","    # Adam optimizator sa weight decay-om (L2 regularizacija)\n","    optimizer = optim.Adam(\n","        model.parameters(),\n","        lr=0.001,           # Stopa uÄenja\n","        weight_decay=1e-4,  # L2 regularizacija\n","        betas=(0.9, 0.999)  # Adam parametri\n","    )\n","\n","    # Scheduler stope uÄenja\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer,\n","        mode='min',         # Smanji LR kada validation loss prestane da opada\n","        factor=0.5,         # PomnoÅ¾i LR sa 0.5\n","        patience=10,        # ÄŒekaj 10 epoha pre smanjivanja\n","    )\n","\n","    return criterion, optimizer, scheduler\n","\n","criterion, optimizer, scheduler = create_training_components(model, train_dataset)\n","\n","print(\"=== Training Components ===\")\n","print(f\"Loss function: {criterion}\")\n","print(f\"Optimizer: {optimizer}\")\n","print(f\"Scheduler: {scheduler}\")\n","print(f\"Class weights: {criterion.weight}\")"],"metadata":{"id":"8OpLdSv7KPRN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Trening Petlja\n","\n","Sada smo spremni da definiÅ¡emo samu trening petlju!\n","\n","Kako bi kod bio Äistiji, definisaÄ‡emo Å¡ta se deÅ¡ava tokom jedne epohe treniranja, a zatim definisati treniranje kao petlju po epohama:"],"metadata":{"id":"pozlR7_YKUaT"}},{"cell_type":"code","source":["def train_epoch(model, train_loader, criterion, optimizer, device):\n","    \"\"\"Treniranje jedne epohe.\"\"\"\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for batch_features, batch_labels in train_loader:\n","        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(batch_features)\n","        loss = criterion(outputs, batch_labels)\n","\n","        # Backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Statistika\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += batch_labels.size(0)\n","        correct += (predicted == batch_labels).sum().item()\n","\n","    epoch_loss = running_loss / len(train_loader)\n","    epoch_acc = 100 * correct / total\n","    return epoch_loss, epoch_acc\n","\n","def validate_epoch(model, val_loader, criterion, device):\n","    \"\"\"Validiraj jednu epohu.\"\"\"\n","    model.eval()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for batch_features, batch_labels in val_loader:\n","            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n","\n","            outputs = model(batch_features)\n","            loss = criterion(outputs, batch_labels)\n","\n","            running_loss += loss.item()\n","            _, predicted = torch.max(outputs, 1)\n","            total += batch_labels.size(0)\n","            correct += (predicted == batch_labels).sum().item()\n","\n","    epoch_loss = running_loss / len(val_loader)\n","    epoch_acc = 100 * correct / total\n","    return epoch_loss, epoch_acc"],"metadata":{"id":"sjd1C04nKvq3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sada Ä‡emo definisati trening sa validacijom:"],"metadata":{"id":"Cn7jCitxKwe5"}},{"cell_type":"code","source":["def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,\n","                num_epochs=100, patience=15):\n","    \"\"\"Cela trening petlja sa ranim zaustavljanjem\"\"\"\n","\n","    # PraÄ‡enje treninga\n","    history = {\n","        'train_loss': [], 'train_acc': [],\n","        'val_loss': [], 'val_acc': []\n","    }\n","\n","    best_val_loss = float('inf')\n","    best_model_state = None\n","    epochs_without_improvement = 0\n","\n","    print(f\"ğŸš€ Starting Training\")\n","    print(f\"Target: >90% validation accuracy\")\n","    print(\"-\" * 60)\n","\n","    for epoch in range(num_epochs):\n","        # Faza treniranja\n","        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n","\n","        # Faza validacije\n","        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n","\n","        # AÅ¾uriranje stope uÄenja\n","        scheduler.step(val_loss)\n","\n","        # BeleÅ¾i istoriju treninga\n","        history['train_loss'].append(train_loss)\n","        history['train_acc'].append(train_acc)\n","        history['val_loss'].append(val_loss)\n","        history['val_acc'].append(val_acc)\n","\n","        # Logika ranog zaustavljanja\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            best_model_state = model.state_dict().copy()\n","            epochs_without_improvement = 0\n","        else:\n","            epochs_without_improvement += 1\n","\n","        # PrikaÅ¾i progres\n","        if (epoch + 1) % 10 == 0 or epoch == 0:\n","            print(f\"Epoch [{epoch+1:3d}/{num_epochs}] | \"\n","                  f\"Train: Loss={train_loss:.4f}, Acc={train_acc:.1f}% | \"\n","                  f\"Val: Loss={val_loss:.4f}, Acc={val_acc:.1f}% | \"\n","                  f\"LR={optimizer.param_groups[0]['lr']:.6f}\")\n","\n","        # Rano zaustavljanje\n","        if epochs_without_improvement >= patience:\n","            print(f\"\\nâ° Early stopping after {epoch+1} epochs (no improvement for {patience} epochs)\")\n","            break\n","\n","    # UÄitaj najbolji model\n","    if best_model_state is not None:\n","        model.load_state_dict(best_model_state)\n","        print(f\"âœ… Loaded best model (val_loss={best_val_loss:.4f})\")\n","\n","    print(\"-\" * 60)\n","    print(f\"ğŸ¯ Training completed!\")\n","\n","    return history"],"metadata":{"id":"b07TzghLK-cf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Definisali smo logiku treniranja. KonaÄno, hajde da istreniramo naÅ¡ model:"],"metadata":{"id":"qx3W06d5K_Mi"}},{"cell_type":"code","source":["# Treniraj model\n","training_history = train_model(\n","    model, train_loader, val_loader, criterion, optimizer, scheduler,\n","    num_epochs=100, patience=15\n",")"],"metadata":{"id":"6uoD0Ig_LMPq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Vizualizacija Treninga\n","\n","Pogledajmo kako je proÅ¡lo treniranje.\n","\n","*Zapamtite: Postoje mnogo sofisticiraniji alati za praÄ‡enje i vizualizaciju treniranja koji su integrisani u samo treniranje i Äine ovaj zadatak mnogo lakÅ¡im. Ali, to je van okvira ovog kursa.*"],"metadata":{"id":"Qp-mXI_QLNKN"}},{"cell_type":"code","source":["# Nacrtaj istoriju treniranja\n","def plot_training_history(history):\n","    \"\"\"Nacrtaj krive treniranja i validacije.\"\"\"\n","    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n","\n","    # Krive gubitka\n","    axes[0].plot(history['train_loss'], label='Training Loss', linewidth=2)\n","    axes[0].plot(history['val_loss'], label='Validation Loss', linewidth=2)\n","    axes[0].set_xlabel('Epoch')\n","    axes[0].set_ylabel('Loss')\n","    axes[0].set_title('Training and Validation Loss')\n","    axes[0].legend()\n","    axes[0].grid(True, alpha=0.3)\n","\n","    # Krive taÄnosti\n","    axes[1].plot(history['train_acc'], label='Training Accuracy', linewidth=2)\n","    axes[1].plot(history['val_acc'], label='Validation Accuracy', linewidth=2)\n","    axes[1].axhline(y=90, color='r', linestyle='--', alpha=0.7, label='Target: 90%')\n","    axes[1].set_xlabel('Epoch')\n","    axes[1].set_ylabel('Accuracy (%)')\n","    axes[1].set_title('Training and Validation Accuracy')\n","    axes[1].legend()\n","    axes[1].grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # IspiÅ¡i finalne rezultate\n","    final_train_acc = history['train_acc'][-1]\n","    final_val_acc = history['val_acc'][-1]\n","    best_val_acc = max(history['val_acc'])\n","\n","    print(f\"ğŸ“Š Training Results:\")\n","    print(f\"   Final Training Accuracy:   {final_train_acc:.2f}%\")\n","    print(f\"   Final Validation Accuracy: {final_val_acc:.2f}%\")\n","    print(f\"   Best Validation Accuracy:  {best_val_acc:.2f}%\")\n","\n","    if best_val_acc >= 90:\n","        print(f\"   ğŸ‰ SUCCESS! Target achieved!\")\n","    else:\n","        print(f\"   âš ï¸  Target not reached (need {90-best_val_acc:.1f}% more)\")\n","\n","plot_training_history(training_history)"],"metadata":{"id":"qjufljjGLYgx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sada, na osnovu ovih rezultata, da li Å¾elimo da promenimo neÅ¡to u naÅ¡em modelu (veliÄinu, stopu uÄenja, broj slojeva, itd.) da ga uÄinimo boljim, ili smo zadovoljni rezultatima?\n","\n","Ako niste zadovoljni, ili Å¾elite da eksperimentiÅ¡ete viÅ¡e, slobodno menjajte parametre u kodu i pokrenite treniranje ponovo.\n","\n","Ako ste zadovoljni, hajde da preÄ‘emo na evaluaciju naÅ¡eg modela na podacima koje nikad ranije nije video."],"metadata":{"id":"Jr9hB1VsMOHN"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"cCq6YCNUL0tk"}},{"cell_type":"markdown","source":["## 7.5 Evaluacija Klasifikatora"],"metadata":{"id":"rjSxebIsL2is"}},{"cell_type":"markdown","source":["### Sveobuhvatna Evaluacija Modela\n","\n","Vreme je da **testiramo naÅ¡ model** davanjem podataka koje nije video tokom treniranja (posmatrajte to kao novoprikupljene podatke sa detektora, za koje je neko veÄ‡ izvrÅ¡io ruÄnu analizu), i vidimo koliko dobro naÅ¡ klasifikator funkcioniÅ¡e:"],"metadata":{"id":"Nez0pnjfMEmF"}},{"cell_type":"code","source":["def comprehensive_evaluation(model, test_loader, device, class_names):\n","    \"\"\"IzvrÅ¡ava sveobuhvatnu evaluaciju modela.\"\"\"\n","    model.eval()\n","    all_predictions = []\n","    all_labels = []\n","    all_probabilities = []\n","\n","    print(\"ğŸ” Evaluating model on test set...\")\n","\n","    with torch.no_grad():\n","        for batch_features, batch_labels in test_loader:\n","            batch_features = batch_features.to(device)\n","\n","            # IzraÄunaj predviÄ‘anja i verovatnoÄ‡e\n","            outputs = model(batch_features)\n","            probabilities = F.softmax(outputs, dim=1)\n","            _, predicted = torch.max(outputs, 1)\n","\n","            all_predictions.extend(predicted.cpu().numpy())\n","            all_labels.extend(batch_labels.numpy())\n","            all_probabilities.extend(probabilities.cpu().numpy())\n","\n","    all_predictions = np.array(all_predictions)\n","    all_labels = np.array(all_labels)\n","    all_probabilities = np.array(all_probabilities)\n","\n","    # IzraÄunaj metrike\n","    test_accuracy = 100 * (all_predictions == all_labels).mean()\n","    print(f\"ğŸ¯ Test Accuracy: {test_accuracy:.2f}%\")\n","    print(\"-\" * 50)\n","\n","    # Detaljan izveÅ¡taj klasifikacije\n","    print(\"ğŸ“‹ Classification Report:\")\n","    print(classification_report(all_labels, all_predictions, target_names=class_names))\n","\n","    # Matrica konfuzije\n","    cm = confusion_matrix(all_labels, all_predictions)\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=class_names, yticklabels=class_names)\n","    plt.title('Confusion Matrix')\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.show()\n","\n","    # Analiza po klasama\n","    print(\"ğŸ”¬ Per-Class Analysis:\")\n","    for i, class_name in enumerate(class_names):\n","        class_mask = all_labels == i\n","        class_accuracy = (all_predictions[class_mask] == i).mean() * 100\n","        class_confidence = all_probabilities[class_mask, i].mean()\n","        print(f\"   {class_name:8s}: Accuracy={class_accuracy:.1f}%, Avg Confidence={class_confidence:.3f}\")\n","\n","    return {\n","        'test_accuracy': test_accuracy,\n","        'predictions': all_predictions,\n","        'labels': all_labels,\n","        'probabilities': all_probabilities,\n","        'confusion_matrix': cm\n","    }\n","\n","# Evaluiraj model\n","evaluation_results = comprehensive_evaluation(model, test_loader, device, model.class_names)"],"metadata":{"id":"fdtrQRDyNY_x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Analiza sa StanoviÅ¡ta Fizike\n","\n","U redu, sada imamo rezultate i njihovu statistiÄku analizu, ali kako da interpretiramo ovo iz perspektive naÅ¡eg domena (fizike)?\n","\n","Uvek je vaÅ¾no razumeti rezultate i performanse, bilo da su dobre ili loÅ¡e."],"metadata":{"id":"Ygxg0Gs7Nhpp"}},{"cell_type":"code","source":["def physics_analysis(model, test_loader, device, feature_names, class_names):\n","    \"\"\"Analiziraj predviÄ‘anja modela iz fiziÄke perspektive.\"\"\"\n","    model.eval()\n","    feature_data = []\n","    predictions_data = []\n","    labels_data = []\n","    confidence_data = []\n","\n","    with torch.no_grad():\n","        for batch_features, batch_labels in test_loader:\n","            batch_features_norm = batch_features.to(device)\n","\n","            # IzraÄunaj predviÄ‘anja\n","            outputs = model(batch_features_norm)\n","            probabilities = F.softmax(outputs, dim=1)\n","            _, predicted = torch.max(outputs, 1)\n","            confidence = torch.max(probabilities, 1)[0]\n","\n","            # ÄŒuvaj podatke (denormalizuj karakteristike za interpretaciju)\n","            batch_features_orig = batch_features * train_std + train_mean\n","            feature_data.extend(batch_features_orig.numpy())\n","            predictions_data.extend(predicted.cpu().numpy())\n","            labels_data.extend(batch_labels.numpy())\n","            confidence_data.extend(confidence.cpu().numpy())\n","\n","    feature_data = np.array(feature_data)\n","    predictions_data = np.array(predictions_data)\n","    labels_data = np.array(labels_data)\n","    confidence_data = np.array(confidence_data)\n","\n","    print(\"ğŸ”¬ Physics-Informed Analysis\")\n","    print(\"-\" * 40)\n","\n","    # Analiziraj pogreÅ¡ne klasifikacije\n","    misclassified = predictions_data != labels_data\n","    print(f\"Misclassified samples: {misclassified.sum()} / {len(labels_data)} ({misclassified.mean()*100:.1f}%)\")\n","\n","    if misclassified.sum() > 0:\n","        print(\"\\nMisclassification Analysis:\")\n","        for true_class in range(3):\n","            for pred_class in range(3):\n","                if true_class != pred_class:\n","                    mask = (labels_data == true_class) & (predictions_data == pred_class)\n","                    count = mask.sum()\n","                    if count > 0:\n","                        avg_confidence = confidence_data[mask].mean()\n","                        print(f\"   {class_names[true_class]} â†’ {class_names[pred_class]}: \"\n","                              f\"{count:3d} samples (confidence: {avg_confidence:.3f})\")\n","\n","    # Analiza vaÅ¾nosti karakteristika\n","    print(f\"\\nğŸ“Š Feature Analysis by Particle Type:\")\n","    for class_id, class_name in enumerate(class_names):\n","        class_mask = labels_data == class_id\n","        print(f\"\\n{class_name} characteristics:\")\n","        for feat_id, feat_name in enumerate(feature_names):\n","            mean_val = feature_data[class_mask, feat_id].mean()\n","            std_val = feature_data[class_mask, feat_id].std()\n","            print(f\"   {feat_name:20s}: {mean_val:6.2f} Â± {std_val:5.2f}\")\n","\n","    # Analiza pouzdanosti\n","    print(f\"\\nğŸ¯ Model Confidence Analysis:\")\n","    for class_id, class_name in enumerate(class_names):\n","        class_mask = predictions_data == class_id\n","        if class_mask.sum() > 0:\n","            avg_confidence = confidence_data[class_mask].mean()\n","            print(f\"   {class_name:8s} predictions: {avg_confidence:.3f} average confidence\")\n","\n","# IzvrÅ¡i analizu sa stanoviÅ¡ta fizike\n","physics_analysis(model, test_loader, device, full_dataset.feature_names, model.class_names)"],"metadata":{"id":"6RuWbY5tODfC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Å ta moÅ¾ete da kaÅ¾ete o naÅ¡em modelu i fizici koju smo nauÄili iz njega?"],"metadata":{"id":"-jevEb0sOHoJ"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"IoTBeSKdOP8K"}},{"cell_type":"markdown","source":["## 7.6 Izvoz i Implementacija Modela\n","\n","Kada ste istrenirali i evaluirali svoj model i oseÄ‡ate da je spreman za koriÅ¡Ä‡enje kao alat, treba da ga **implementirate**. Postoji nekoliko biblioteka koje rukuju Äuvanjem, izvozom i implementacijom modela, kao i uÄitavanjem i koriÅ¡Ä‡enjem u drugim projektima. MeÄ‘utim, koristiÄ‡emo PyTorch-ove ugraÄ‘ene metode za ovo."],"metadata":{"id":"yOwPewElOU_r"}},{"cell_type":"markdown","source":["### ÄŒuvanje Modela"],"metadata":{"id":"xTAUag06O81E"}},{"cell_type":"code","source":["# SaÄuvaj istrenirani model\n","def save_model(model, filepath, training_history, normalization_stats):\n","    \"\"\"Save model with all necessary information for deployment.\"\"\"\n","\n","    save_dict = {\n","        'model_state_dict': model.state_dict(),\n","        'model_config': model.get_info(),\n","        'training_history': training_history,\n","        'normalization_mean': normalization_stats[0],\n","        'normalization_std': normalization_stats[1],\n","        'class_names': model.class_names,\n","        'feature_names': model.feature_names\n","    }\n","\n","    torch.save(save_dict, filepath)\n","    print(f\"ğŸ’¾ Model saved to: {filepath}\")\n","\n","# SaÄuvaj model\n","model_save_path = \"particle_classifier.pth\"\n","save_model(model, model_save_path, training_history, (train_mean, train_std))"],"metadata":{"id":"581FhxYuO-vM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### UÄitavanje i KoriÅ¡Ä‡enje Modela"],"metadata":{"id":"fyAM4GJ1PBFD"}},{"cell_type":"code","source":["def load_and_predict(filepath, sample_features):\n","    \"\"\"UÄitaj model i napravi predviÄ‘anja na novim podacima.\"\"\"\n","    # UÄitaj model\n","    save_dict = torch.load(filepath, map_location=device)\n","\n","    # Rekreiraj arhitekturu modela na osnovu saÄuvanih podataka\n","    loaded_model = ParticleClassifier().to(device)\n","    loaded_model.load_state_dict(save_dict['model_state_dict'])\n","    loaded_model.eval()\n","\n","    # IzraÄunaj statistiku normalizacije\n","    norm_mean = save_dict['normalization_mean']\n","    norm_std = save_dict['normalization_std']\n","    class_names = save_dict['class_names']\n","\n","    # Normalizuj ulaz\n","    sample_normalized = (sample_features - norm_mean) / norm_std\n","    sample_normalized = sample_normalized.to(device)\n","\n","    # Napravi predviÄ‘anje\n","    with torch.no_grad():\n","        outputs = loaded_model(sample_normalized.unsqueeze(0))\n","        probabilities = F.softmax(outputs, dim=1)\n","        predicted_class = torch.argmax(probabilities, dim=1).item()\n","        confidence = probabilities.max().item()\n","\n","    return {\n","        'predicted_class': predicted_class,\n","        'predicted_particle': class_names[predicted_class],\n","        'confidence': confidence,\n","        'all_probabilities': probabilities.squeeze().cpu().numpy()\n","    }"],"metadata":{"id":"4SPqKt9iPHow"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Testiranje Implementacije"],"metadata":{"id":"LkVwh-srPaJr"}},{"cell_type":"code","source":["# Testiraj Implementaciju\n","print(\"\\nğŸš€ Testing Model Deployment:\")\n","print(\"-\" * 30)\n","\n","# Napravi nekoliko uzoraka oÄitavanja iz detektora\n","sample_readings = torch.tensor([\n","    [10.5, 0.75, 2.2, 8.0],  # LiÄi na elektron\n","    [2.5, 0.20, 2.4, 12.0], # LiÄi na mion\n","    [6.8, 0.50, 2.9, 7.0]   # LiÄi na pion\n","]).to(device)\n","\n","for i, reading in enumerate(sample_readings):\n","    result = load_and_predict(model_save_path, reading)\n","    print(f\"Sample {i+1}: {result['predicted_particle']} \"\n","          f\"(confidence: {result['confidence']:.3f})\")\n","    print(f\"   Probabilities: Electron={result['all_probabilities'][0]:.3f}, \"\n","          f\"Muon={result['all_probabilities'][1]:.3f}, \"\n","          f\"Pion={result['all_probabilities'][2]:.3f}\")\n","\n","print(\"\\nâœ… Model successfully deployed and tested!\")"],"metadata":{"id":"YUk6U7JCPisL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"hSL5yU4VPjdD"}},{"cell_type":"markdown","source":["# KljuÄni ZakljuÄci"],"metadata":{"id":"YvgHRbFNPkC6"}},{"cell_type":"markdown","source":["## Pristup reÅ¡avanju problema:\n","\n","1. Razumeti problem\n","2. Prikupiti i razumeti podatke\n","3. Koristiti profesionalne PyTorch radne tokove za podatke\n","4. Dizajnirati odgovarajuÄ‡u arhitekturu mreÅ¾e na osnovu poznavanja problema i podataka\n","5. Trenirati koristeÄ‡i najbolje navike (normalizacija, regularizacija)\n","6. Sveobuhvatno evaluirati\n","7. Implementirati sa pravilnim Äuvanjem/uÄitavanjem modela"],"metadata":{"id":"DsrnIF2IPsqG"}},{"cell_type":"markdown","source":["## Najbolje PyTorch navike:\n","\n","- Koristite Dataset i DataLoader klase\n","- Podelite podatke na trening/validaciju/test skupove\n","- Normalizacijujte karakteristike\n","- Odaberite dobru veliÄinu batch-a\n","- Koristite GPU-ove kad god moÅ¾ete\n","- Primenite rano zaustavljanje i scheduling stope uÄenja\n","- Koristite sveobuhvatne metrike za evaluaciju\n","- Pravilno izvezite modele za dalju implementaciju"],"metadata":{"id":"styClB5qQA_G"}},{"cell_type":"markdown","source":["## Uvid iz Fizike:\n","\n","- Neuronske mreÅ¾e mogu da nauÄe sloÅ¾ene procese bez analitiÄkih reÅ¡enja\n","- Korelacije karakteristika odraÅ¾avaju pravu fiziku\n","- Interpretabilnost modela je kljuÄna u nauci\n","- Analiza pouzdanosti pomaÅ¾e identifikaciji sistematskih greÅ¡aka"],"metadata":{"id":"20w82ydEQODP"}},{"cell_type":"markdown","source":["## SledeÄ‡i koraci:\n","\n","Na sledeÄ‡em kursu (KSMF2), nauÄiÄ‡emo viÅ¡e o sloÅ¾enijim arhitekturama modela koje su osnova za moderni AI. NauÄiÄ‡emo kako da ih implementiramo koristeÄ‡i sloÅ¾enije PyTorch apstrakcije i joÅ¡ profesionalnije pipeline-ove sa viÅ¡e GPU-ova, Torch Lightning, itd."],"metadata":{"id":"Fg8Z_aiNRSI0"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"QcWVtS-8Q2Ji"}},{"cell_type":"markdown","source":["# Samostalni Rad\n","\n","Kao veÅ¾bu, pokuÅ¡ajte da primenite sve Å¡to ste nauÄili u pravljenju vaÅ¡ih sopstvenih modela za stvarne, ili izmiÅ¡ljene primere. MoÅ¾ete Äak proÄ‡i kroz ovaj primer i pokuÅ¡ati da eksperimentiÅ¡ete sa dataset-om, modelom, treniranjem i evaluacijom."],"metadata":{"id":"GUho5VhyQ3rX"}}]}